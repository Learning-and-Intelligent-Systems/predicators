"""The core algorithm for learning a collection of NSRT data structures."""

from __future__ import annotations

import logging
from typing import List, Set

from predicators.src import utils
from predicators.src.nsrt_learning.option_learning import create_option_learner
from predicators.src.nsrt_learning.sampler_learning import learn_samplers
from predicators.src.nsrt_learning.segmentation import segment_trajectory
from predicators.src.nsrt_learning.side_predicate_learning import \
    BackchainingSidePredicateLearner, \
    PredictionErrorHillClimbingSidePredicateLearner, \
    PreserveSkeletonsHillClimbingSidePredicateLearner, SidePredicateLearner
from predicators.src.nsrt_learning.strips_learning import \
    learn_strips_operators
from predicators.src.settings import CFG
from predicators.src.structs import NSRT, LowLevelTrajectory, \
    PartialNSRTAndDatastore, Predicate, Task


def learn_nsrts_from_data(trajectories: List[LowLevelTrajectory],
                          train_tasks: List[Task], predicates: Set[Predicate],
                          sampler_learner: str) -> Set[NSRT]:
    """Learn NSRTs from the given dataset of low-level transitions, using the
    given set of predicates."""
    logging.info(f"\nLearning NSRTs on {len(trajectories)} trajectories...")

    # STEP 1: Apply predicates to data, producing a dataset of abstract states.
    ground_atom_dataset = utils.create_ground_atom_dataset(
        trajectories, predicates)

    # STEP 2: Segment each trajectory in the dataset based on changes in
    #         either predicates or options. If we are doing option learning,
    #         then the data will not contain options, so this segmenting
    #         procedure only uses the predicates.
    segmented_trajs = [
        segment_trajectory(traj) for traj in ground_atom_dataset
    ]

    # Each entry in ground_atom_dataset is a tuple of (low-level trajectory,
    # low-level ground atoms sequence). We remove the latter, because
    # it's prone to causing bugs -- we should rarely care about the
    # low-level ground atoms sequence after segmentation.
    low_level_trajs = [ll_traj for ll_traj, _ in ground_atom_dataset]
    del ground_atom_dataset

    # If performing goal-conditioned sampler learning, we need to attach the
    # goals to the segments.
    if CFG.sampler_learning_use_goals:
        for segment_traj, ll_traj in zip(segmented_trajs, low_level_trajs):
            # If the trajectory is not a demonstration, it does not have a
            # known goal (e.g., it was generated by random replay data), so we
            # won't attach a goal to the segment.
            if ll_traj.is_demo:
                goal = train_tasks[ll_traj.train_task_idx].goal
                for segment in segment_traj:
                    segment.set_goal(goal)

    segments = [seg for segs in segmented_trajs for seg in segs]

    # STEP 3: Cluster the data by effects, jointly producing one STRIPSOperator,
    #         Datastore, and OptionSpec per cluster. These items are then
    #         used to initialize PartialNSRTAndDatastore objects (PNADs).
    #         Note: The OptionSpecs here are extracted directly from the data.
    #         If we are doing option learning, then the data will not contain
    #         options, and so the option_spec fields are just the specs of a
    #         DummyOption. We need a default dummy because future steps require
    #         the option_spec field to be populated, even if just with a dummy.
    pnads = learn_strips_operators(
        segments,
        verbose=(CFG.option_learner != "no_learning"
                 or CFG.side_predicate_learner != "no_learning"))

    # STEP 4: Learn side predicates for the operators and update PNADs. These
    #         are predicates whose truth value becomes unknown (for *any*
    #         grounding not explicitly in effects) upon operator application.
    if CFG.side_predicate_learner != "no_learning":
        assert CFG.option_learner == "no_learning", \
            "Can't learn options and side predicates together."
        if CFG.side_predicate_learner == "prediction_error_hill_climbing":
            side_pred_learner: SidePredicateLearner = \
                PredictionErrorHillClimbingSidePredicateLearner(
                    pnads, trajectories, train_tasks, predicates,
                    segmented_trajs)
        elif CFG.side_predicate_learner == "preserve_skeletons_hill_climbing":
            side_pred_learner = \
                PreserveSkeletonsHillClimbingSidePredicateLearner(
                    pnads, trajectories, train_tasks, predicates,
                    segmented_trajs)
        elif CFG.side_predicate_learner == "backchaining":
            side_pred_learner = BackchainingSidePredicateLearner(
                pnads, trajectories, train_tasks, predicates, segmented_trajs)
        else:
            raise ValueError(
                f"side_predicate_learner {CFG.side_predicate_learner} not " +
                "implemented")
        pnads = side_pred_learner.sideline()

    # STEP 5: Learn options (option_learning.py) and update PNADs.
    _learn_pnad_options(pnads)  # in-place update

    # STEP 6: Learn samplers (sampler_learning.py) and update PNADs.
    _learn_pnad_samplers(pnads, sampler_learner)  # in-place update

    # STEP 7: Log and return the NSRTs.
    nsrts = [pnad.make_nsrt() for pnad in pnads]
    logging.info("\nLearned NSRTs:")
    for nsrt in nsrts:
        logging.info(nsrt)
    logging.info("")
    return set(nsrts)


def _learn_pnad_options(pnads: List[PartialNSRTAndDatastore]) -> None:
    logging.info("\nDoing option learning...")
    option_learner = create_option_learner()
    strips_ops = []
    datastores = []
    for pnad in pnads:
        strips_ops.append(pnad.op)
        datastores.append(pnad.datastore)
    option_specs = option_learner.learn_option_specs(strips_ops, datastores)
    assert len(option_specs) == len(pnads)
    # Replace the option_specs in the PNADs.
    for pnad, option_spec in zip(pnads, option_specs):
        pnad.option_spec = option_spec
    # Seed the new parameterized option parameter spaces.
    for parameterized_option, _ in option_specs:
        parameterized_option.params_space.seed(CFG.seed)
    # Update the segments to include which option is being executed.
    for datastore, spec in zip(datastores, option_specs):
        for (segment, _) in datastore:
            # Modifies segment in-place.
            option_learner.update_segment_from_option_spec(segment, spec)
    logging.info("\nLearned operators with option specs:")
    for pnad in pnads:
        logging.info(pnad)


def _learn_pnad_samplers(pnads: List[PartialNSRTAndDatastore],
                         sampler_learner: str) -> None:
    logging.info("\nDoing sampler learning...")
    strips_ops = []
    datastores = []
    option_specs = []
    for pnad in pnads:
        strips_ops.append(pnad.op)
        datastores.append(pnad.datastore)
        option_specs.append(pnad.option_spec)
    samplers = learn_samplers(strips_ops, datastores, option_specs,
                              sampler_learner)
    assert len(samplers) == len(strips_ops)
    # Replace the samplers in the PNADs.
    for pnad, sampler in zip(pnads, samplers):
        pnad.sampler = sampler
